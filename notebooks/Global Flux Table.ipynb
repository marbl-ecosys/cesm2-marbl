{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a Table of Global Fluxes\n",
    "\n",
    "This notebook reads in the CESM1 historical run (for CMIP5),\n",
    "the ensemble of 11 CESM2 historical runs (for CMIP6),\n",
    "and also the four SSP CESM2 ensembles (for CMIP6).\n",
    "A table is generated containing values listed [issue #6](https://github.com/marbl-ecosys/cesm2-marbl/issues/6)\n",
    "\n",
    "\n",
    "> * Net primary production (PgC/yr) (`photoC_TOT_zint`)\n",
    "> * Diatom primary production (%)   (`photoC_diat_zint`)\n",
    "> * Sinking POC at 100 m (PgC/yr)   (`POC_FLUX_100m`)\n",
    "> * Sinking CaCO3 at 100 m (PgC/yr) (`CaCO3_FLUX_100m`)\n",
    "> * Rain ratio (CaCO3/POC) 100 m    (ratio of two above)\n",
    "> * Nitrogen fixation (TgN/yr)      (`diaz_Nfix`)\n",
    "> * Nitrogen deposition (TgN/yr)    (`NOx_FLUX` + `NHy_FLUX`)\n",
    "> * Denitrification (TgN/yr)        (`DENITRIF`)\n",
    "> * N cycle imbalance = deposition + fixation - denitrification (TgN/yr) # deposition = N* [see Kristen's notebook -- Biological Diagnostics?]\n",
    "> * Airâ€“sea CO2 flux (PgC yr21)     (`FG_CO2`)\n",
    "> * Mean ocean oxygen (mmol/m^3)    (`O2`)\n",
    "> * Volume where O2 <80 mmol/m^3 (10^15 m^3) # based on others\n",
    "> * Volume where O2 <60 mmol/m^3 (10^15 m^3) # based on others\n",
    "> * Volume where O2 <5 mmol/m^3 (10^15 m^3)  # based on others\n",
    "\n",
    "Values will be computed one at a time, due to an issue with `xr.merge` and trying to read multiple variables at once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook uses several python packages\n",
    "\n",
    "The watermark package shows the version number used to help others recreate this environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "import cftime\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import cmocean\n",
    "\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "import esmlab\n",
    "\n",
    "import intake\n",
    "import intake_esm\n",
    "import ncar_jobqueue\n",
    "from dask.distributed import Client\n",
    "import pint\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -a \"Mike Levy\" -d -iv -m -g -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spin up a dask cluster\n",
    "\n",
    "Some of these computations take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = ncar_jobqueue.NCARCluster(project='P93300606')\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the intake_esm datastores\n",
    "\n",
    "The `intake_esm` package is used to help identify which files belong in each experiment.\n",
    "The `get_var_from_catalogs()` function is a wrapper to read specific files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogs = dict()\n",
    "#cesm2 = intake.open_esm_datastore('/glade/collections/cmip/catalog/intake-esm-datastore/catalogs/campaign_via_glade-cmip6_NOT_CMORIZED.json')\n",
    "catalogs['cesm2'] = intake.open_esm_datastore('/glade/work/mlevy/intake-esm-collection/json/campaign-cesm2-cmip6-timeseries.json')\n",
    "\n",
    "#cesm1 = intake.open_esm_datastore('/glade/collections/cmip/catalog/intake-esm-datastore/catalogs/glade-cmip5_NOT_CMORIZED.json')\n",
    "catalogs['cesm1'] = intake.open_esm_datastore('/glade/work/mlevy/intake-esm-collection/json/glade-cesm1-cmip5-timeseries.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: 1991-01-01 0:00:00 is the time stamp on the Dec 1990 monthly average\n",
    "#       So slice(\"1991\", \"2001\") would actually return Dec 1990 - Nov 2000\n",
    "#       Specifying a day mid-month gets us to Jan 1991 - Dec 2000\n",
    "#       (this can be verified by looking at time bounds)\n",
    "time_slices_hist = slice(\"1990-01-15\", \"2000-01-15\")\n",
    "time_slices_SSP = slice(\"2090-01-15\", \"2100-01-15\")\n",
    "time_slices = dict()\n",
    "\n",
    "time_slices['cesm1_hist'] = time_slices_hist\n",
    "time_slices['cesm2_hist'] = time_slices_hist\n",
    "time_slices['cesm2_SSP1-2.6'] = time_slices_SSP\n",
    "time_slices['cesm2_SSP2-4.5'] = time_slices_SSP\n",
    "time_slices['cesm2_SSP3-7.0'] = time_slices_SSP\n",
    "time_slices['cesm2_SSP5-8.5'] = time_slices_SSP\n",
    "\n",
    "def get_var_from_catalogs(catalogs, variable):\n",
    "    datasets = dict()\n",
    "    \n",
    "    dq = dict()\n",
    "    # CESM1 is historical only, CESM2 also has SSPs\n",
    "    dq['cesm1'] = catalogs['cesm1'].search(experiment=['historical'], variable=variable).to_dataset_dict(cdf_kwargs={'chunks':{'time': 48}})\n",
    "    dq['cesm2'] = catalogs['cesm2'].search(experiment=['historical', 'SSP1-2.6', 'SSP2-4.5', 'SSP3-7.0', 'SSP5-8.5'], variable=variable).to_dataset_dict(cdf_kwargs={'chunks':{'time': 48}})\n",
    "\n",
    "    # Define datasets\n",
    "    datasets['cesm1_hist'] = dq['cesm1']['ocn.historical.pop.h']\n",
    "    # UNCOMMENT LINES BELOW WHEN HAPPY WITH FULL TABLE\n",
    "#     datasets['cesm2_hist'] = dq['cesm2']['ocn.historical.pop.h']\n",
    "#     datasets['cesm2_SSP1-2.6'] = dq['cesm2']['ocn.SSP1-2.6.pop.h']\n",
    "#     datasets['cesm2_SSP2-4.5'] = dq['cesm2']['ocn.SSP2-4.5.pop.h']\n",
    "#     datasets['cesm2_SSP3-7.0'] = dq['cesm2']['ocn.SSP3-7.0.pop.h']\n",
    "    datasets['cesm2_SSP5-8.5'] = dq['cesm2']['ocn.SSP5-8.5.pop.h']\n",
    "\n",
    "    keep_vars = ['z_t', 'z_t_150m', 'dz', 'TAREA', 'TLONG', 'TLAT', 'time', 'time_bound', 'member_id', 'ctrl_member_id'] + [variable]\n",
    "    for exp in datasets:\n",
    "        datasets[exp] = datasets[exp].drop([v for v in datasets[exp].variables if v not in keep_vars]).sel(time=time_slices[exp])\n",
    "\n",
    "    return(datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pint import UnitRegistry\n",
    "units = UnitRegistry()\n",
    "\n",
    "# Set up units\n",
    "integral_units = dict()\n",
    "integral_units['area'] = dict()\n",
    "integral_units['volume'] = dict()\n",
    "\n",
    "# Read in any variable to get dataset containing TAREA and z_t\n",
    "tmp_data = get_var_from_catalogs(catalogs, 'IRON_FLUX')\n",
    "\n",
    "for exp in tmp_data:\n",
    "    integral_units['area'][exp] = units[tmp_data[exp]['TAREA'].attrs['units']]\n",
    "    integral_units['volume'][exp] = integral_units['area'][exp] * units[tmp_data[exp]['z_t'].attrs['units']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Table Computations\n",
    "\n",
    "In this section, we compute each of the requested values for each dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Net primary production (PgC/yr)\n",
    "\n",
    "CESM1 doesn't have `photoC_TOT_zint`\n",
    "\n",
    "#### Diatom primary production (%)\n",
    "\n",
    "CESM1 doesn't have `photoC_diat_zint`\n",
    "\n",
    "#### Sinking POC at 100 m (PgC/yr)\n",
    "\n",
    "CESM1 doesn't have `POC_FLUX_100m`\n",
    "\n",
    "#### Sinking CaCO3 at 100 m (PgC/yr)\n",
    "\n",
    "CESM1 doesn't have `CaCO3_FLUX_100m`\n",
    "\n",
    "#### Rain ratio (CaCO3/POC) 100 m\n",
    "\n",
    "Missing necessary vars to compute\n",
    "\n",
    "#### Nitrogen deposition (TgN/yr)\n",
    "\n",
    "#### Denitrification (TgN/yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = dict()\n",
    "\n",
    "# Process for updating intake-esm catalog\n",
    "#       1. download all data from HPSS via get_ocn_cmip5_files.sh\n",
    "#       2. rm /glade/u/home/mlevy/.intake_esm/collections/CESM1-CMIP5.nc\n",
    "#       3. regenerate it via Anderson's legacy intake-esm\n",
    "#       4. re-run build intake collections notebook\n",
    "#       5. commit change to .csv.gz in /glade/work/mlevy/intake-esm-collection/csv.gz/\n",
    "\n",
    "vars = ['diaz_Nfix', 'NOx_FLUX', 'NHy_FLUX', 'DENITRIF']\n",
    "for var in vars:\n",
    "    all_data[var] = get_var_from_catalogs(catalogs, var)\n",
    "\n",
    "# Verify time bounds for each experiment\n",
    "for exp in all_data[vars[0]]:\n",
    "    bounds = list(all_data[vars[0]][exp].time_bound.values[ind] for ind in [(0,0), (-1,1)])\n",
    "    print(f'Experiment: {exp}\\nBounds\\n----\\n{bounds}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_global_averages(datasets, integral_units, variable):\n",
    "    experiments = list(datasets[variable].keys())\n",
    "    wgts = datasets[variable][experiments[0]]['TAREA'].isel(time=0)\n",
    "    dims = ['nlat', 'nlon']\n",
    "    unit_key = 'area'\n",
    "    if 'z_t_150m' in datasets[variable][experiments[0]][variable].dims:\n",
    "        wgts = wgts * datasets[variable][experiments[0]]['dz'].isel(time=0, z_t=slice(0,15))\n",
    "        wgts = wgts.rename({'z_t' : 'z_t_150m'})\n",
    "        dims.append('z_t_150m')\n",
    "        unit_key = 'volume'\n",
    "    elif 'z_t' in datasets[variable][experiments[0]][variable].dims:\n",
    "        wgts = wgts * datasets[variable][experiments[0]]['dz'].isel(time=0)\n",
    "        dims.append('z_t')\n",
    "        unit_key = 'volume'\n",
    "    glb_avg = dict()\n",
    "    new_units = dict()\n",
    "    for exp in experiments:\n",
    "        glb_avg[exp] = esmlab.weighted_sum(datasets[variable][exp][variable], dim=dims, weights=wgts).to_dataset(name=variable)\n",
    "        old_units = units[datasets[variable][exp][variable].attrs['units']]\n",
    "        new_units[exp] = old_units*integral_units[unit_key][exp]\n",
    "        glb_avg[exp]\n",
    "    return glb_avg, new_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_avg = dict()\n",
    "new_units = dict()\n",
    "for variable in all_data:\n",
    "    glb_avgs, new_units[variable] = compute_global_averages(all_data, integral_units, variable)\n",
    "    ann_avg[variable] = dict()\n",
    "    for exp in glb_avgs:\n",
    "        glb_avgs[exp]['time_bound'] = all_data[variable][exp]['time_bound']\n",
    "        ann_avg[variable][exp] = esmlab.resample(glb_avgs[exp], freq='ann')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce Data Sets\n",
    "\n",
    "The following table shows global averages (also averaged over specified time slices)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# CELL WHERE I TRY TO FIGURE OUT HOW TO CONVERT [substance] TO [mass] \n",
    "\n",
    "units.define('gram_nitrogen = 14*units.gram/units.mol = gN')\n",
    "\n",
    "# variable = 'NOx_FLUX'\n",
    "# exp = 'cesm1_hist'\n",
    "# (ann_avg[variable][exp][variable].mean(['time', 'member_id']).values *\n",
    "#  new_units[variable][exp]\n",
    "# )\n",
    "\n",
    "print((5 * units['mol']).to('gN'))\n",
    "print((5 * units['nanomol']).to('TgN'))\n",
    "print((5 * units['nanomol/s']).to('TgN/year'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define final units\n",
    "final_units = dict()\n",
    "final_units['DENITRIF'] = 'Tg/year'\n",
    "final_units['NOx_FLUX'] = 'Tg/year'\n",
    "final_units['NHy_FLUX'] = 'Tg/year'\n",
    "final_units['diaz_Nfix'] = 'Tg/year'\n",
    "\n",
    "# Define conversion factors\n",
    "conversions = dict()\n",
    "\n",
    "### TODO: RUN CONVERSIONS BY MATT\n",
    "# Final units are TgN / yr\n",
    "gN = 14 * units['g'] / units['mol']\n",
    "conversions['DENITRIF'] = gN\n",
    "conversions['NOx_FLUX'] = gN\n",
    "conversions['NHy_FLUX'] = gN\n",
    "conversions['diaz_Nfix'] = gN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_avg['diaz_Nfix'][exp]['diaz_Nfix'].mean(['time', 'member_id']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "experiments = list(ann_avg[vars[0]].keys())\n",
    "diagnostic_values = dict()\n",
    "for exp in experiments:\n",
    "    diagnostic_values[exp] = dict()\n",
    "    # Compute each value by hand\n",
    "    print(f'Computing Nfixation for {exp}')\n",
    "    diagnostic_values[exp]['Nitrogen fixation (TgN yr$^{-1}$)'] =  \\\n",
    "        (ann_avg['diaz_Nfix'][exp]['diaz_Nfix'].mean(['time', 'member_id']).values *\n",
    "         new_units['diaz_Nfix'][exp] *\n",
    "         conversions['diaz_Nfix']\n",
    "        ).to(final_units['diaz_Nfix'])\n",
    "    \n",
    "    print(f'Computing Ndep for {exp}')\n",
    "    diagnostic_values[exp]['Nitrogen deposition (TgN yr$^{-1}$)'] = \\\n",
    "        (ann_avg['NOx_FLUX'][exp]['NOx_FLUX'].mean(['time', 'member_id']).values *\n",
    "         new_units['NOx_FLUX'][exp] *\n",
    "         conversions['NOx_FLUX']\n",
    "        ).to(final_units['NOx_FLUX']) + \\\n",
    "        (ann_avg['NHy_FLUX'][exp]['NHy_FLUX'].mean(['time', 'member_id']).values *\n",
    "         new_units['NHy_FLUX'][exp] *\n",
    "         conversions['NHy_FLUX']\n",
    "        ).to(final_units['NHy_FLUX'])\n",
    "\n",
    "    print(f'Computing Denitrif for {exp}')\n",
    "    diagnostic_values[exp]['Denitrification (TgN yr$^{-1}$)'] = \\\n",
    "        (ann_avg['DENITRIF'][exp]['DENITRIF'].mean(['time', 'member_id']).values *\n",
    "         new_units['DENITRIF'][exp] *\n",
    "         conversions['DENITRIF']\n",
    "        ).to(final_units['DENITRIF'])\n",
    "    \n",
    "    print(f'Computing Nitrogen Cycle imbalance for {exp}')\n",
    "    diagnostic_values[exp]['N cycle imbalance* (TgN yr$^{-1}$)'] = diagnostic_values[exp]['Nitrogen deposition (TgN yr$^{-1}$)'] + \\\n",
    "                                                                   diagnostic_values[exp]['Nitrogen fixation (TgN yr$^{-1}$)'] - \\\n",
    "                                                                   diagnostic_values[exp]['Denitrification (TgN yr$^{-1}$)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill a dict with (data, units) tuple [unit conversion comes later]\n",
    "table_dict = dict()\n",
    "diagnostic_columns = ['Gross primary production (PgC yr$^{-1}$)',\n",
    "                      'Sinking POC at 100 m (PgC yr$^{-1}$)',\n",
    "                      'Sinking CaCO$_3$ at 100 m (PgC yr$^{-1}$)',\n",
    "                      'Rain ratio (CaCO$_3$/POC) at 100 m',\n",
    "                      'Nitrogen fixation (TgN yr$^{-1}$)',\n",
    "                      'Nitrogen deposition (TgN yr$^{-1}$)',\n",
    "                      'Denitrification (TgN yr$^{-1}$)',\n",
    "                      'N cycle imbalance* (TgN yr$^{-1}$)',\n",
    "                      'Airâ€“sea CO2 flux (PgC yr$^{-1}$)',\n",
    "                      'Diatom primary production (%)',\n",
    "                      'Mean ocean oxygen ($\\mu$M)',\n",
    "                      'OMZ volume (10$^{16}$ m$^3$; <20 $\\mu$M)'\n",
    "                     ]\n",
    "experiment_longnames={'cesm1_hist' : '1990s (CESM1)', 'cesm2_SSP5-8.5' : 'RCP85 2090s (CESM2)'}\n",
    "\n",
    "table_dict['Diagnostic'] = []\n",
    "for variable in diagnostic_columns:\n",
    "    table_dict['Diagnostic'].append(variable)\n",
    "    for exp in experiments:\n",
    "        if experiment_longnames[exp] not in table_dict:\n",
    "            table_dict[experiment_longnames[exp]] = []\n",
    "        try:\n",
    "            table_dict[experiment_longnames[exp]].append(diagnostic_values[exp][variable].magnitude)\n",
    "        except:\n",
    "            table_dict[experiment_longnames[exp]].append('-')\n",
    "\n",
    "pd.DataFrame(table_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cesm2-marbl]",
   "language": "python",
   "name": "conda-env-cesm2-marbl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
